<!DOCTYPE html>
<html lang="zh-Hans">







<head>
	
	
	<link rel="stylesheet" href="/css/allinone.min.css">

	

	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">

	<title>学习爬虫Scrapy[官网教程] | Ghcoder</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="Ghcoder">
	<meta name="description" content="">

	
	<meta name="keywords" content="">
	

	
	<link rel="shortcut icon" href="https://i.loli.net/2017/11/26/5a19c0b50432e.png">
	<link rel="apple-touch-icon" href="https://i.loli.net/2017/11/26/5a19c0b50432e.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Ghcoder">
	<meta property="og:type" content="article">
	<meta property="og:title" content="学习爬虫Scrapy[官网教程] | Ghcoder">
	<meta property="og:description" content="">
	<meta property="og:url" content="http://www.ghcoder.com/2017/05/25/20170525/">

	
	<meta property="article:published_time" content="2017-05-25T10:05:00+08:00"> 
	<meta property="article:author" content="Ghcoder">
	<meta property="article:published_first" content="Ghcoder, /2017/05/25/20170525/">
	
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header outer" style="z-index: 999">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                <a href="/" title="Home">HOME</a>
                
            </li>
            
            
            <li>
                <a href="/about" title="ABOUT">ABOUT</a>
            </li>
            
            <li>
                <a href="/archives" title="ARCHIVES">ARCHIVES</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button">
        <a href="#search" class="subscribe-button" style="margin: 0 10px;">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="subscribe-button" style="margin: 0 10px;">Search ...</a>
         
        
<div class="social-links">
    
    <a class="social-link" title="weibo" href="https://weibo.com/xzhih" target="_blank" rel="noopener">
        <svg viewbox="0 0 1141 1024" xmlns="http://www.w3.org/2000/svg"><path d="M916.48 518.144q27.648 21.504 38.912 51.712t9.216 62.976-14.336 65.536-31.744 59.392q-34.816 48.128-78.848 81.92t-91.136 56.32-94.72 35.328-89.6 18.944-75.264 7.68-51.712 1.536-49.152-2.56-68.096-10.24-78.336-21.504-79.872-36.352-74.24-55.296-59.904-78.848q-16.384-29.696-22.016-63.488t-5.632-86.016q0-22.528 7.68-51.2t27.136-63.488 53.248-75.776 86.016-90.112q51.2-48.128 105.984-85.504t117.248-57.856q28.672-10.24 63.488-11.264t57.344 11.264q10.24 11.264 19.456 23.04t12.288 29.184q3.072 14.336 0.512 27.648t-5.632 26.624-5.12 25.6 2.048 22.528q17.408 2.048 33.792-1.536t31.744-9.216 31.232-11.776 33.28-9.216q27.648-5.12 54.784-4.608t49.152 7.68 36.352 22.016 17.408 38.4q2.048 14.336-2.048 26.624t-8.704 23.04-7.168 22.016 1.536 23.552q3.072 7.168 14.848 13.312t27.136 12.288 32.256 13.312 29.184 16.384zM658.432 836.608q26.624-16.384 53.76-45.056t44.032-64 18.944-75.776-20.48-81.408q-19.456-33.792-47.616-57.344t-62.976-37.376-74.24-19.968-80.384-6.144q-78.848 0-139.776 16.384t-105.472 43.008-72.192 60.416-38.912 68.608q-11.264 33.792-6.656 67.072t20.992 62.976 42.496 53.248 57.856 37.888q58.368 25.6 119.296 32.256t116.224 0.512 100.864-21.504 74.24-33.792zM524.288 513.024q20.48 8.192 38.912 18.432t32.768 27.648q10.24 12.288 17.92 30.72t10.752 39.424 1.536 42.496-9.728 38.912q-8.192 18.432-19.968 37.376t-28.672 35.328-40.448 29.184-57.344 18.944q-61.44 11.264-117.76-11.264t-88.064-74.752q-12.288-39.936-13.312-70.656t16.384-66.56q13.312-27.648 40.448-51.712t62.464-38.912 75.264-17.408 78.848 12.8zM361.472 764.928q37.888 3.072 57.856-18.432t21.504-48.128-15.36-47.616-52.736-16.896q-27.648 3.072-43.008 23.552t-17.408 43.52 9.728 42.496 39.424 21.504zM780.288 6.144q74.752 0 139.776 19.968t113.664 57.856 76.288 92.16 27.648 122.88q0 33.792-16.384 50.688t-35.328 17.408-35.328-14.336-16.384-45.568q0-40.96-22.528-77.824t-59.392-64.512-84.48-43.52-96.768-15.872q-31.744 0-47.104-15.36t-14.336-34.304 18.944-34.304 51.712-15.36zM780.288 169.984q95.232 0 144.384 48.64t49.152 146.944q0 30.72-10.24 43.52t-22.528 11.264-22.528-14.848-10.24-35.84q0-60.416-34.816-96.256t-93.184-35.84q-19.456 0-28.672-10.752t-9.216-23.04 9.728-23.04 28.16-10.752z"/></svg>
    </a>
    
    
    <a class="social-link" title="github" href="https://github.com/xzhih" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<main id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <section class="post-full-meta">
                <time class="post-full-meta-date" datetime="2017-05-25T02:37:12.000Z" itemprop="datePublished">
                    2017-05-25
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/日志/">日志</a>&nbsp;&nbsp;
                
                
            </section>
            <h1 class="post-full-title">学习爬虫Scrapy[官网教程]</h1>
        </header>
        <article class="post-full no-image">
            
            <section class="post-full-content">
                <div id="lightgallery" class="markdown-body">
                    <h4 id="1-学习爬虫框架-Scrapy"><a href="#1-学习爬虫框架-Scrapy" class="headerlink" title="1.学习爬虫框架 Scrapy"></a>1.学习爬虫框架 Scrapy</h4><ul>
<li>前几天一直在正Django的框架，现在基本上已经ok了，如果我们需要自己创建属于自己的网站、需要前台展示数据，后台可以编辑数据，可以插入到数据库，可以建立自己的数据类型，使用Django已经够了，那么现在有一个很重要的难题：数据从哪里来？怎么获取？如何存取？-&gt; <code>Scrapy</code>能够很好满足我们这些需求。</li>
<li>目前文档是线上最新的版本:<code>Scrapy 1.3</code>[<a href="https://docs.scrapy.org/en/latest/]" target="_blank" rel="noopener">https://docs.scrapy.org/en/latest/]</a></li>
</ul>
<h4 id="1-1-什么是Scrapy"><a href="#1-1-什么是Scrapy" class="headerlink" title="1.1 什么是Scrapy"></a>1.1 什么是Scrapy</h4><ul>
<li><code>scrapy</code>是一个web端抓取网站数据的框架，可以用来数据挖掘，信息处理等等</li>
</ul>
<a id="more"></a>
<h4 id="1-2-安装Scrapy"><a href="#1-2-安装Scrapy" class="headerlink" title="1.2 安装Scrapy"></a>1.2 安装Scrapy</h4><ul>
<li>安装scrapy官网建议两种途径：</li>
</ul>
<p>1.使用<code>conda</code>:<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">conda <span class="keyword">install</span> -c conda-forge scrapy</span><br></pre></td></tr></table></figure></p>
<p>2.使用<code>pip</code>: </p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pip <span class="keyword">install</span> Scrapy</span><br></pre></td></tr></table></figure>
<ul>
<li>官方建议，我们在安装<code>Scrapy</code>的时候，最好安装自己创建的虚拟环境中<code>a dedicated virtualenv</code>，这样至少不会与系统的包产生冲突。</li>
<li><code>virtualenv</code>的安装网址为：[<a href="http://sourabhbajaj.com/mac-setup/Python/virtualenv.html]" target="_blank" rel="noopener">http://sourabhbajaj.com/mac-setup/Python/virtualenv.html]</a></li>
</ul>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1.</span></span><br><span class="line">cd myproject/</span><br><span class="line"><span class="comment">//2.</span></span><br><span class="line">virtualenv venv </span><br><span class="line"><span class="comment">// 如果你的系统已经安装了python2已经python3，但是你现在想建立一个python3的环境</span></span><br><span class="line"><span class="comment">// virtualenv -p python3 envname</span></span><br><span class="line"><span class="comment">//3.</span></span><br><span class="line">source venv<span class="meta-keyword">/bin/</span>activate</span><br><span class="line"><span class="comment">//4.</span></span><br><span class="line">pip install Scrapy</span><br></pre></td></tr></table></figure>
<ul>
<li>执行完上面的4行命令，此时应该就可以安装好了<code>Scrapy</code>了。</li>
<li>执行一下<code>pip list</code>，看一下安装<code>scrapy</code>系统默认给我们安装了什么：</li>
</ul>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">(<span class="selector-tag">venv</span>) ➜  <span class="selector-tag">venv</span> <span class="selector-tag">pip</span> <span class="selector-tag">list</span></span><br><span class="line"><span class="selector-tag">Package</span>          <span class="selector-tag">Version</span></span><br><span class="line"><span class="selector-tag">----------------</span> <span class="selector-tag">-------</span></span><br><span class="line"><span class="selector-tag">appdirs</span>          1<span class="selector-class">.4</span><span class="selector-class">.3</span></span><br><span class="line"><span class="selector-tag">asn1crypto</span>       0<span class="selector-class">.22</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">attrs</span>            17<span class="selector-class">.1</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">Automat</span>          0<span class="selector-class">.6</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">cffi</span>             1<span class="selector-class">.10</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">constantly</span>       15<span class="selector-class">.1</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">cryptography</span>     1<span class="selector-class">.8</span><span class="selector-class">.1</span></span><br><span class="line"><span class="selector-tag">cssselect</span>        1<span class="selector-class">.0</span><span class="selector-class">.1</span></span><br><span class="line"><span class="selector-tag">enum34</span>           1<span class="selector-class">.1</span><span class="selector-class">.6</span></span><br><span class="line"><span class="selector-tag">idna</span>             2<span class="selector-class">.5</span></span><br><span class="line"><span class="selector-tag">incremental</span>      16<span class="selector-class">.10</span><span class="selector-class">.1</span></span><br><span class="line"><span class="selector-tag">ipaddress</span>        1<span class="selector-class">.0</span><span class="selector-class">.18</span></span><br><span class="line"><span class="selector-tag">lxml</span>             3<span class="selector-class">.7</span><span class="selector-class">.3</span></span><br><span class="line"><span class="selector-tag">packaging</span>        16<span class="selector-class">.8</span></span><br><span class="line"><span class="selector-tag">parsel</span>           1<span class="selector-class">.2</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">pip</span>              9<span class="selector-class">.0</span><span class="selector-class">.1</span></span><br><span class="line"><span class="selector-tag">pyasn1</span>           0<span class="selector-class">.2</span><span class="selector-class">.3</span></span><br><span class="line"><span class="selector-tag">pyasn1-modules</span>   0<span class="selector-class">.0</span><span class="selector-class">.8</span></span><br><span class="line"><span class="selector-tag">pycparser</span>        2<span class="selector-class">.17</span></span><br><span class="line"><span class="selector-tag">PyDispatcher</span>     2<span class="selector-class">.0</span><span class="selector-class">.5</span></span><br><span class="line"><span class="selector-tag">pyOpenSSL</span>        17<span class="selector-class">.0</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">pyparsing</span>        2<span class="selector-class">.2</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">queuelib</span>         1<span class="selector-class">.4</span><span class="selector-class">.2</span></span><br><span class="line"><span class="selector-tag">Scrapy</span>           1<span class="selector-class">.3</span><span class="selector-class">.3</span></span><br><span class="line"><span class="selector-tag">service-identity</span> 16<span class="selector-class">.0</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">setuptools</span>       35<span class="selector-class">.0</span><span class="selector-class">.2</span></span><br><span class="line"><span class="selector-tag">six</span>              1<span class="selector-class">.10</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">Twisted</span>          17<span class="selector-class">.1</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">w3lib</span>            1<span class="selector-class">.17</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">wheel</span>            0<span class="selector-class">.29</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">zope</span><span class="selector-class">.interface</span>   4<span class="selector-class">.4</span><span class="selector-class">.1</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>lxml</code>[<a href="http://lxml.de/]" target="_blank" rel="noopener">http://lxml.de/]</a>, 高效的<code>xml</code>和<code>html</code>的解析框架，最低版本为<code>3.4</code></li>
<li><code>parsel</code>[<a href="https://pypi.python.org/pypi/parsel]" target="_blank" rel="noopener">https://pypi.python.org/pypi/parsel]</a> ,在lxml的封装，解析<code>html/xml</code>的数据</li>
<li><code>w3lib</code>[<a href="https://pypi.python.org/pypi/w3lib]" target="_blank" rel="noopener">https://pypi.python.org/pypi/w3lib]</a>, 处理页面的url以及encodings</li>
<li><code>twisted</code>[<a href="https://twistedmatrix.com/trac/]" target="_blank" rel="noopener">https://twistedmatrix.com/trac/]</a>, 异步的网络请求框架。最低版本为：<code>14.0</code></li>
<li><code>cryptography</code>和<code>pyOpenSSL</code>(最低版本为<code>0.14</code>) 多重网络安全</li>
</ul>
<h4 id="1-3-开始抓取数据："><a href="#1-3-开始抓取数据：" class="headerlink" title="1.3 开始抓取数据："></a>1.3 开始抓取数据：</h4><ul>
<li>现在我们开始爬取页面，这里就爬取一下这个页面：<code>http://quotes.toscrape.com/</code>，这个网站列举了很多著名的导演，这个抓取的目的有下面几个：</li>
</ul>
<ol>
<li>创建一个新的<code>Scrapy</code>对象.</li>
<li>写一个<code>spider</code>对象抓取网站，并且解析数据</li>
<li>用命令行导出抓取的数据</li>
<li>改变规则，递归的抓取数据</li>
<li>运用<code>spider</code>的参数</li>
</ol>
<h4 id="1-3-1-新建scrapy项目"><a href="#1-3-1-新建scrapy项目" class="headerlink" title="1.3.1 新建scrapy项目"></a>1.3.1 新建scrapy项目</h4><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/<span class="regexp">/1.</span></span><br><span class="line"><span class="regexp">scrapy startproject tutorial</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">/</span><span class="regexp">/2.</span></span><br><span class="line"><span class="regexp">New Scrapy project 'tutorial', using template directory '/</span>Users/gonghuan/Desktop/myproject/venv/<span class="class"><span class="keyword">lib</span>/<span class="title">python2</span>.7/<span class="title">site</span>-<span class="title">packages</span>/<span class="title">scrapy</span>/<span class="title">templates</span>/<span class="title">project</span>', <span class="title">created</span> <span class="title">in</span>:</span></span><br><span class="line">    /Users/gonghuan/Desktop/myproject/venv/tutorial</span><br><span class="line"></span><br><span class="line">You can start your first spider <span class="symbol">with:</span></span><br><span class="line">    cd tutorial</span><br><span class="line">    scrapy genspider example example.com</span><br></pre></td></tr></table></figure>
<h4 id="1-3-2-创建我们第一个spider"><a href="#1-3-2-创建我们第一个spider" class="headerlink" title="1.3.2 创建我们第一个spider"></a>1.3.2 创建我们第一个spider</h4><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="title">scrapy</span>.<span class="title">Spider</span>):</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> <span class="symbol">urls:</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=<span class="keyword">self</span>.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[-<span class="number">2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        with open(filename, <span class="string">'wb'</span>) as <span class="symbol">f:</span></span><br><span class="line">            f.write(response.body)</span><br><span class="line">        <span class="keyword">self</span>.log(<span class="string">'Saved file %s'</span> % filename)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>spider</code>是<code>Scrapy</code>用来抓取数据的类</li>
<li>必须要继承<code>scrapy.Spider</code>，并且要初始化请求，抓取规则，解析数据的规则等等</li>
<li><code>name</code>被赋值为<code>quotes</code>,这是作为项目的唯一标示符，必须唯一的。</li>
<li><code>start_requests</code>的方法，必须要返回一个可以递归的<code>request</code>请求。</li>
<li><code>parse</code>的方法，用来处理下载下来的<code>response</code>，<code>response</code>的参数保存在<code>TextResponse</code>的实例中。</li>
<li><code>parse</code>的作用：1: 解析<code>response</code>,并将爬去下来的<code>dics</code>解析成我们需要的数据，2: 并且找到新的url数据，并且创建新的<code>request</code></li>
<li>最后执行<code>scrapy crawl quotes</code>,这个命令<code>quotes</code>就是我们刚才定义的name,然后他们将会向<code>quotes.toscrape.com</code>这个域名发起请求,终端也会出现下面的返回：</li>
</ul>
<figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">... (omitted for brevity)</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET http://quotes.toscrape.com/robots.txt&gt; (referer: None)</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/2/&gt; (referer: None)</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [quotes] DEBUG: Saved file quotes<span class="string">-1</span>.html</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [quotes] DEBUG: Saved file quotes<span class="string">-2</span>.html</span><br><span class="line">2016<span class="string">-12</span><span class="string">-16</span> 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<ul>
<li>此时检查项目的文件夹，会出现<code>quotes-1.html、quotes-2.html</code>这样的两个文件，就代表已经成功抓取下来了。</li>
<li>刚才在<code>start_requests</code>的函数中，我们返回了<code>scrapy.Request</code>的对象，当这些请求一旦接受到服务器返回的<code>response</code>的时候，就会立刻调用callback的方法，也就是<code>parse</code>的方法，这个方法会包含刚才我们的请求的<code>url</code>以及相应的参数。</li>
</ul>
<h4 id="1-3-3-简写代码"><a href="#1-3-3-简写代码" class="headerlink" title="1.3.3 简写代码"></a>1.3.3 简写代码</h4><ul>
<li>其实我们发现<code>start_requests</code>其实就是通过对于的<code>url</code>生成相应的<code>scrapy.Request</code>的对象，但其实我们可以不用实现<code>start_requests</code>的方法，我们可以直接定义一个<code>start_urls</code>的列表，里面的元素就是相应的请求<code>url</code>,一旦你定义了这个对象，<code>start_requests</code>会默认从<code>start_urls</code>来获取<code>url</code></li>
<li>即使在你的代码中没有指定的callback函数，<code>parse</code>的函数也会默认来处理每个url发起的请求，主要也是因为<code>parse</code>是系统默认的方法（当你没有准确的指定callback）</li>
<li>修改为如下的代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure>
<h4 id="1-3-4-解析数据"><a href="#1-3-4-解析数据" class="headerlink" title="1.3.4 解析数据"></a>1.3.4 解析数据</h4><ul>
<li>官方的建议，最好的解析是在<code>shell</code> [<a href="https://docs.scrapy.org/en/latest/topics/shell.html#topics-shell]" target="_blank" rel="noopener">https://docs.scrapy.org/en/latest/topics/shell.html#topics-shell]</a> 的操作下，在我们刚才创建的虚拟环境下执行如下的脚本<code>scrapy shell &quot;http://quotes.toscrape.com/page/1/&quot;</code></li>
<li>看到如下的终端返回：</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[ ... Scrapy log here ... ]</span><br><span class="line"><span class="number">2016</span>-<span class="number">09</span>-<span class="number">19</span> <span class="number">12</span>:<span class="number">09</span>:<span class="number">27</span> [scrapy<span class="selector-class">.core</span><span class="selector-class">.engine</span>] DEBUG: Crawled (<span class="number">200</span>) &lt;GET http:<span class="comment">//quotes.toscrape.com/page/1/&gt; (referer: None)</span></span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy<span class="selector-class">.Request</span>, scrapy<span class="selector-class">.Selector</span>, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy<span class="selector-class">.crawler</span><span class="selector-class">.Crawler</span> <span class="selector-tag">object</span> at <span class="number">0</span>x7fa91d888c90&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET http:<span class="comment">//quotes.toscrape.com/page/1/&gt;</span></span><br><span class="line">[s]   response   &lt;<span class="number">200</span> http:<span class="comment">//quotes.toscrape.com/page/1/&gt;</span></span><br><span class="line">[s]   settings   &lt;scrapy<span class="selector-class">.settings</span><span class="selector-class">.Settings</span> <span class="selector-tag">object</span> at <span class="number">0</span>x7fa91d888c10&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider <span class="string">'default'</span> at <span class="number">0</span>x7fa91c8af990&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   fetch(req_or_url) Fetch request (or URL) and update local objects</span><br><span class="line">[s]   view(response)    View response <span class="keyword">in</span> <span class="selector-tag">a</span> browser</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>我们如何获取<code>response</code>里面的元素呢？可以通过<code>css</code> [<a href="https://www.w3.org/TR/selectors/]" target="_blank" rel="noopener">https://www.w3.org/TR/selectors/]</a></li>
<li>执行<code>response.css(&#39;title&#39;)</code>,就可以在终端看到如下的返回：</li>
</ul>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span></span><br></pre></td></tr></table></figure>
<ul>
<li>执行<code>response.css(&#39;title&#39;)</code>返回的是一个类似列表的一个东西，这个东西叫做<code>SelectorList</code>,这个列表里面就是搜索的对象，这些对象是<code>Selector</code>,这些<code>Selector</code>就是包装这些<code>XML/HTML</code>的外壳。你可以直接通过<code>Selector</code>直接获得里面的值：</li>
</ul>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; response.css(<span class="string">'title'</span>).extract()</span><br><span class="line">[<span class="string">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>你会发现还是一个列表，不是我们想要的值，这时我们就需要对css进行过滤，添加<code>::text</code>，就表示我们想要的只是<code>&lt;title&gt;</code>标签中对应的值</li>
</ul>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; response.css(<span class="string">'title::text'</span>).extract()</span><br><span class="line">[<span class="string">'Quotes to Scrape'</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>返回的还是一个列表，但是你确定你需要的是第一个元素的话，可以这样直接使用<code>extract_first</code>取得列表中的元素,这样为了避免产生<code>IndexError</code>：</li>
</ul>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; response.css(<span class="string">'title::text'</span>).extract_first()</span><br><span class="line"><span class="string">'Quotes to Scrape'</span></span><br></pre></td></tr></table></figure>
<ul>
<li>除了使用<code>extract()</code>以及<code>extract_first()</code>,还是可以使用<code>re()</code>，就是通过正则来筛选解析的数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>response.css(<span class="string">'title::text'</span>).re(<span class="string">r'Quotes.*'</span>)</span><br><span class="line">[<span class="string">'Quotes to Scrape'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>response.css(<span class="string">'title::text'</span>).re(<span class="string">r'Q\w+'</span>)</span><br><span class="line">[<span class="string">'Quotes'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>response.css(<span class="string">'title::text'</span>).re(<span class="string">r'(\w+) to (\w+)'</span>)</span><br><span class="line">[<span class="string">'Quotes'</span>, <span class="string">'Scrape'</span>]</span><br></pre></td></tr></table></figure>
<h4 id="1-3-4-除了使用CSS，你也可以使用XPath来查找元素"><a href="#1-3-4-除了使用CSS，你也可以使用XPath来查找元素" class="headerlink" title="1.3.4 除了使用CSS，你也可以使用XPath来查找元素"></a>1.3.4 除了使用<code>CSS</code>，你也可以使用<code>XPath</code>来查找元素</h4><ul>
<li>例如：</li>
</ul>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.xpath('<span class="comment">//title')</span></span><br><span class="line"><span class="meta">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span></span><br><span class="line">&gt;&gt;&gt; response.xpath('<span class="comment">//title/text()').extract_first()</span></span><br><span class="line">'Quotes <span class="keyword">to</span> Scrape'</span><br></pre></td></tr></table></figure>
<ul>
<li><code>XPath</code>是非常形象具体，并且功能强大的，<code>CSS</code>的选择器也是通过一些接口来转化为<code>XPath</code>的，虽然<code>XPath</code>没有<code>CSS</code>那么出名，但是它还是非常强大的，官方也是建议学习使用<code>XPath</code>，给出相关的链接：</li>
</ul>
<ol>
<li>[<a href="https://docs.scrapy.org/en/latest/topics/selectors.html#topics-selectors]" target="_blank" rel="noopener">https://docs.scrapy.org/en/latest/topics/selectors.html#topics-selectors]</a></li>
<li>[<a href="http://zvon.org/comp/r/tut-XPath_1.html]" target="_blank" rel="noopener">http://zvon.org/comp/r/tut-XPath_1.html]</a></li>
<li>[<a href="http://plasmasturm.org/log/xpath101/]" target="_blank" rel="noopener">http://plasmasturm.org/log/xpath101/]</a></li>
</ol>
<h4 id="1-3-5-解析数据"><a href="#1-3-5-解析数据" class="headerlink" title="1.3.5 解析数据"></a>1.3.5 解析数据</h4><ul>
<li>现在你已经知道了一些关于选择器，获取数据的方法，现在就可以完善我们之前的爬虫了</li>
<li>刚才我们爬去的的页面中，你会发现每个<code>http://quotes.toscrape.com</code>都含有一下的<code>html</code>：</li>
</ul>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">div</span> class=<span class="string">"quote"</span>&gt;</span><br><span class="line">    &lt;span class=<span class="string">"text"</span>&gt;“The world <span class="keyword">as</span> we have created <span class="keyword">it</span> is <span class="keyword">a</span> <span class="built_in">process</span> <span class="keyword">of</span> our</span><br><span class="line">    thinking. It cannot be changed <span class="keyword">without</span> changing our thinking.”&lt;/span&gt;</span><br><span class="line">    &lt;span&gt;</span><br><span class="line">        <span class="keyword">by</span> &lt;small class=<span class="string">"author"</span>&gt;Albert Einstein&lt;/small&gt;</span><br><span class="line">        &lt;<span class="keyword">a</span> href=<span class="string">"/author/Albert-Einstein"</span>&gt;(about)&lt;/<span class="keyword">a</span>&gt;</span><br><span class="line">    &lt;/span&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> class=<span class="string">"tags"</span>&gt;</span><br><span class="line">        Tags:</span><br><span class="line">        &lt;<span class="keyword">a</span> class=<span class="string">"tag"</span> href=<span class="string">"/tag/change/page/1/"</span>&gt;change&lt;/<span class="keyword">a</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">a</span> class=<span class="string">"tag"</span> href=<span class="string">"/tag/deep-thoughts/page/1/"</span>&gt;deep-thoughts&lt;/<span class="keyword">a</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">a</span> class=<span class="string">"tag"</span> href=<span class="string">"/tag/thinking/page/1/"</span>&gt;thinking&lt;/<span class="keyword">a</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">a</span> class=<span class="string">"tag"</span> href=<span class="string">"/tag/world/page/1/"</span>&gt;world&lt;/<span class="keyword">a</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>还是通过<code>shell</code>的方法来测试，执行下面的代码:</li>
</ul>
<figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1.</span></span><br><span class="line">scrapy <span class="built_in">shell</span> 'http:<span class="comment">//quotes.toscrape.com</span></span><br><span class="line"><span class="comment">//2.</span></span><br><span class="line">response.css(<span class="string">"div.quote"</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>当然也可以把筛选后的数据，复制给每个变量：</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">quote</span> = response.css(<span class="string">"div.quote"</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>现在也可以通过解析<code>quote</code>来获得下面的值：<code>title</code>/<code>author</code>/<code>tag</code></li>
</ul>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; title = quote.css(<span class="string">"span.text::text"</span>).extract_first()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; title</span><br><span class="line"><span class="string">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; author = quote.css(<span class="string">"small.author::text"</span>).extract_first()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; author</span><br><span class="line"><span class="string">'Albert Einstein'</span></span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; tags = quote.css(<span class="string">"div.tags a.tag::text"</span>).extract()</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; tags</span><br><span class="line">[<span class="string">'change'</span>, <span class="string">'deep-thoughts'</span>, <span class="string">'thinking'</span>, <span class="string">'world'</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>已经可以知道我们是如何来获取数据的了，现在我们就可以遍历循环，并且将爬去下来的数据插入到我们的Python的字典数据结构中：</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="keyword">for</span> <span class="selector-tag">quote</span> <span class="keyword">in</span> response.css(<span class="string">"div.quote"</span>):</span><br><span class="line">...     text = <span class="selector-tag">quote</span>.css(<span class="string">"span.text::text"</span>).extract_first()</span><br><span class="line">...     author = <span class="selector-tag">quote</span>.css(<span class="string">"small.author::text"</span>).extract_first()</span><br><span class="line">...     tags = <span class="selector-tag">quote</span>.css(<span class="string">"div.tags a.tag::text"</span>).extract()</span><br><span class="line">...     print(dict(text=text, author=author, tags=tags))</span><br><span class="line">&#123;<span class="string">'tags'</span>: [<span class="string">'change'</span>, <span class="string">'deep-thoughts'</span>, <span class="string">'thinking'</span>, <span class="string">'world'</span>], <span class="string">'author'</span>: <span class="string">'Albert Einstein'</span>, <span class="string">'text'</span>: <span class="string">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>&#125;</span><br><span class="line">&#123;<span class="string">'tags'</span>: [<span class="string">'abilities'</span>, <span class="string">'choices'</span>], <span class="string">'author'</span>: <span class="string">'J.K. Rowling'</span>, <span class="string">'text'</span>: <span class="string">'“It is our choices, Harry, that show what we truly are, far more than our abilities.”'</span>&#125;</span><br><span class="line">    ... <span class="selector-tag">a</span> few more of these, omitted <span class="keyword">for</span> brevity</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<h4 id="1-3-5-更新我们的spide代码："><a href="#1-3-5-更新我们的spide代码：" class="headerlink" title="1.3.5 更新我们的spide代码："></a>1.3.5 更新我们的spide代码：</h4><ul>
<li>现在回到我们之前新建的<code>spider</code>的项目中去，到目前为止，我们还真正去获取任何的数据，我们只是做了一件事情，就是讲页面的<code>html</code>的代码保存在本地，我们可以将每个页面的数据，爬去下来，并且将这些数据放下Python的字典的数据结构中，并且返回回去。代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>运行之后看到如下的返回：</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">09</span>-<span class="number">19</span> <span class="number">18</span>:<span class="number">57</span>:<span class="number">19</span> [scrapy<span class="selector-class">.core</span><span class="selector-class">.scraper</span>] DEBUG: Scraped from &lt;<span class="number">200</span> http:<span class="comment">//quotes.toscrape.com/page/1/&gt;</span></span><br><span class="line">&#123;<span class="string">'tags'</span>: [<span class="string">'life'</span>, <span class="string">'love'</span>], <span class="string">'author'</span>: <span class="string">'André Gide'</span>, <span class="string">'text'</span>: <span class="string">'“It is better to be hated for what you are than to be loved for what you are not.”'</span>&#125;</span><br><span class="line"><span class="number">2016</span>-<span class="number">09</span>-<span class="number">19</span> <span class="number">18</span>:<span class="number">57</span>:<span class="number">19</span> [scrapy<span class="selector-class">.core</span><span class="selector-class">.scraper</span>] DEBUG: Scraped from &lt;<span class="number">200</span> http:<span class="comment">//quotes.toscrape.com/page/1/&gt;</span></span><br><span class="line">&#123;<span class="string">'tags'</span>: [<span class="string">'edison'</span>, <span class="string">'failure'</span>, <span class="string">'inspirational'</span>, <span class="string">'paraphrased'</span>], <span class="string">'author'</span>: <span class="string">'Thomas A. Edison'</span>, <span class="string">'text'</span>: <span class="string">"“I have not failed. I've just found 10,000 ways that won't work.”"</span>&#125;</span><br></pre></td></tr></table></figure>
<h4 id="1-3-6-保存数据"><a href="#1-3-6-保存数据" class="headerlink" title="1.3.6 保存数据"></a>1.3.6 保存数据</h4><ul>
<li>最简单的保存形式就是通过<code>Feed exports</code> [<a href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#topics-feed-exports]" target="_blank" rel="noopener">https://docs.scrapy.org/en/latest/topics/feed-exports.html#topics-feed-exports]</a></li>
<li>这里我们可以执行下面的代码保存为<code>json</code>的格式：</li>
</ul>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.json</span></span><br></pre></td></tr></table></figure>
<ul>
<li>此时在文件中就会出现一个名叫<code>quotes.json</code>的文件，其实就是我们刚才爬去下来的数据。</li>
<li>其实在一些简单的爬虫项目中，这样写，其实已经足够了，但是在一些复杂的大型项目中，可以写<code>Item Pipeline</code>[<a href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html#topics-item-pipeline]" target="_blank" rel="noopener">https://docs.scrapy.org/en/latest/topics/item-pipeline.html#topics-item-pipeline]</a>, 其实这个功能就是对应的项目的中<code>tutorial/pipelines.py</code>, <code>scrapy</code>项目默认会帮你创建的。</li>
</ul>
<h4 id="1-3-7-获取更多的url"><a href="#1-3-7-获取更多的url" class="headerlink" title="1.3.7 获取更多的url"></a>1.3.7 获取更多的url</h4><ul>
<li>其实刚才在项目中，我们只是爬去了两个url，并且也知道如何去解析他们，但是可能我们需要的是爬去整个网站的url，比如我们在爬去一个页面的时候，遇到这样的<code>html</code>,我们就需要计算并且获取对应的<code>url</code>:</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"pager"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"next"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/page/2/"</span>&gt;</span>Next <span class="tag">&lt;<span class="name">span</span> <span class="attr">aria-hidden</span>=<span class="string">"true"</span>&gt;</span>&amp;rarr;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>此时你可能需要获取的是<code>a</code>里面对应的<code>href</code>的值：</li>
</ul>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line"><span class="string">'/page/2/'</span></span><br></pre></td></tr></table></figure>
<ul>
<li>现在我们可以修改我们的spider的代码了，并且不需要指定几个url了，我们需要将这些逻辑都放到<code>parse</code>的函数中去：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<ul>
<li>上面的代码很容易看出，当解析完数据之后，我们就会寻找<code>下一页</code>的<code>url</code>,并且发现这里写的是一个相对的url，这里可以通过<code>urljoin()</code>这个函数来拼接url，并且<code>yields</code>回去一个新的request，当拿到的<code>respsonse</code>又会回到<code>parse</code>的函数中来解析</li>
<li>scrapy的下载机制：当你<code>yields</code>一个新的请求，scrapy会发送改请求，并注册一个回调方法，以便在完成的时候能够解析他。</li>
</ul>
<h4 id="1-3-8-简化发送的请求"><a href="#1-3-8-简化发送的请求" class="headerlink" title="1.3.8 简化发送的请求"></a>1.3.8 简化发送的请求</h4><ul>
<li>为了简化发送的请求，我们可以用<code>response.follow</code>, 而不是新建一个新的<code>Request</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'span small::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<ul>
<li>与<code>scrapy.Request</code>不同，<code>response.follow</code>是支持相对路径，其实就是这个<code>follow</code>它会替我们做<code>response.urljoin</code>,并且<code>response.follow</code>返回是一个<code>Request</code>的实例。</li>
<li>之前的代码，取的是列表中的第一项元素，但是我们也可以枚举这个列表，来调用<code>response.follow</code></li>
</ul>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="symbol">'li</span>.next a::attr(href)'):</span><br><span class="line">    <span class="keyword">yield</span> response.follow(href, callback=<span class="keyword">self</span>.parse)</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 也可以进行简写</span></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> response.css(<span class="symbol">'li</span>.next a'):</span><br><span class="line">    <span class="keyword">yield</span> response.follow(a, callback=<span class="keyword">self</span>.parse)</span><br></pre></td></tr></table></figure>
<ul>
<li>对于抓取作者信息，我们可以自定义自己的回调函数</li>
</ul>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorSpider</span>(<span class="title">scrapy</span>.<span class="title">Spider</span>):</span></span><br><span class="line">    name = <span class="string">'author'</span></span><br><span class="line"></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="comment"># follow links to author pages</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.author + a::attr(href)'</span>)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, <span class="keyword">self</span>.parse_author)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># follow pagination links</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, <span class="keyword">self</span>.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_author</span><span class="params">(<span class="keyword">self</span>, response)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">extract_with_css</span><span class="params">(query)</span></span><span class="symbol">:</span></span><br><span class="line">            <span class="keyword">return</span> response.css(query).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'name'</span>: extract_with_css(<span class="string">'h3.author-title::text'</span>),</span><br><span class="line">            <span class="string">'birthdate'</span>: extract_with_css(<span class="string">'.author-born-date::text'</span>),</span><br><span class="line">            <span class="string">'bio'</span>: extract_with_css(<span class="string">'.author-description::text'</span>),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>这里当找到<code>author</code>相关的链接，我们会回调我们自定义的函数<code>parse_author</code>,在这个函数里，我们顶一个帮助函数，帮助我们具体还获取里面的值，在<code>parse</code>函数中，我们会找到下一页的请求，然后继续发送请求，回调函数还是我们的<code>parse</code>的函数.</li>
<li>这里有个关键的问题，我们不需要担心同一个<code>url</code>发送多次，易导致进入死循环，<code>Scrapy</code>默认是能够过滤已经请求过的url，并且你还可以通过在<code>settings.py</code>的文件中设置<code>DUPEFILTER_CLASS</code> [<a href="https://docs.scrapy.org/en/latest/topics/settings.html#std:setting-DUPEFILTER_CLASS]。" target="_blank" rel="noopener">https://docs.scrapy.org/en/latest/topics/settings.html#std:setting-DUPEFILTER_CLASS]。</a></li>
</ul>
<h4 id="1-3-9-在spider中传递参数"><a href="#1-3-9-在spider中传递参数" class="headerlink" title="1.3.9 在spider中传递参数"></a>1.3.9 在spider中传递参数</h4><ul>
<li>我们可以通过下面的<code>-a</code>来传递参数，这些参数默认是传递到Spider中的<code>__init__</code>函数中去，并且能够成为spider的属性值</li>
</ul>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">scrapy </span>crawl quotes -o quotes-humor.<span class="keyword">json </span>-a tag=humor</span><br></pre></td></tr></table></figure>
<ul>
<li>例如上面的命令，我传递了<code>tag</code>的值，这样我就可以在我的spider项目中能够通过<code>self.tag</code>来获取传进来的值，也可以通过这样的值来请求准确url,其实就是请求的是这样的url: <code>http://quotes.toscrape.com/tag/humor</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        url = <span class="string">'http://quotes.toscrape.com/'</span></span><br><span class="line">        tag = getattr(self, <span class="string">'tag'</span>, <span class="keyword">None</span>)</span><br><span class="line">        <span class="keyword">if</span> tag <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            url = url + <span class="string">'tag/'</span> + tag</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br></pre></td></tr></table></figure>

                </div>
            </section>
        </article>
    </div>

    
    <div style="height: 4vw;width: 100%"></div>
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="学习Android开发基础笔记Tips" href="/2017/05/31/20170531/">
            ← 学习Android开发基础笔记Tips
        </a>
        
        <span class="prev-next-post">•</span>
        
        <a class="next-post" title="学习Django第五/六部分，基本的测试用例[官网教程]" href="/2017/05/17/20170517/">
            学习Django第五/六部分，基本的测试用例[官网教程] →
        </a>
        
    </nav>

    
</main>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-学习爬虫框架-Scrapy"><span class="toc-text">1.学习爬虫框架 Scrapy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-什么是Scrapy"><span class="toc-text">1.1 什么是Scrapy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-安装Scrapy"><span class="toc-text">1.2 安装Scrapy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-开始抓取数据："><span class="toc-text">1.3 开始抓取数据：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-1-新建scrapy项目"><span class="toc-text">1.3.1 新建scrapy项目</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-2-创建我们第一个spider"><span class="toc-text">1.3.2 创建我们第一个spider</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-3-简写代码"><span class="toc-text">1.3.3 简写代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-4-解析数据"><span class="toc-text">1.3.4 解析数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-4-除了使用CSS，你也可以使用XPath来查找元素"><span class="toc-text">1.3.4 除了使用CSS，你也可以使用XPath来查找元素</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-5-解析数据"><span class="toc-text">1.3.5 解析数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-5-更新我们的spide代码："><span class="toc-text">1.3.5 更新我们的spide代码：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-6-保存数据"><span class="toc-text">1.3.6 保存数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-7-获取更多的url"><span class="toc-text">1.3.7 获取更多的url</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-8-简化发送的请求"><span class="toc-text">1.3.8 简化发送的请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-9-在spider中传递参数"><span class="toc-text">1.3.9 在spider中传递参数</span></a></li></ol>
    </div>
</div>



	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(https://i.loli.net/2017/11/26/5a19c56faa29f.jpg)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Ghcoder &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2018/12/12/20181212/">非越狱手机植入动态库</a>
      </li>
      
      
      
      <li>
        <a href="/2018/11/03/20181103/">Swift语法备忘录</a>
      </li>
      
      
      
      <li>
        <a href="/2018/02/23/20180223/">每日一刷LeetCode算法</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(https://i.loli.net/2017/11/26/5a19c56faa29f.jpg)">
    <header class="read-next-card-header" style="padding-bottom: 20px">
        <h3 class="read-next-card-header-title">Categories</h3>
    </header>
    <div class="read-next-card-content">
        <ul>
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/日志/">日志</a></li></ul>
        </ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(https://i.loli.net/2017/11/26/5a19c56faa29f.jpg)">
	<header class="read-next-card-header" style="padding-bottom: 20px">
		<h3 class="read-next-card-header-title">Tag Cloud</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/Android/" style="font-size: 14px;">Android</a> <a href="/tags/Cocoapods/" style="font-size: 14px;">Cocoapods</a> <a href="/tags/Core-Data-Swift/" style="font-size: 21.5px;">Core Data, Swift</a> <a href="/tags/OC/" style="font-size: 14px;">OC</a> <a href="/tags/Obeject-c/" style="font-size: 19px;">Obeject-c</a> <a href="/tags/Object-C/" style="font-size: 14px;">Object-C</a> <a href="/tags/Object-C、加密/" style="font-size: 14px;">Object-C、加密</a> <a href="/tags/Object-c/" style="font-size: 14px;">Object-c</a> <a href="/tags/PHP/" style="font-size: 14px;">PHP</a> <a href="/tags/Python、Django/" style="font-size: 19px;">Python、Django</a> <a href="/tags/Python、Scrapy/" style="font-size: 14px;">Python、Scrapy</a> <a href="/tags/React-Native/" style="font-size: 16.5px;">React Native</a> <a href="/tags/React-Native/" style="font-size: 14px;">React-Native</a> <a href="/tags/Reveal/" style="font-size: 14px;">Reveal</a> <a href="/tags/Swift/" style="font-size: 24px;">Swift</a> <a href="/tags/Swift、Algorithm/" style="font-size: 14px;">Swift、Algorithm</a> <a href="/tags/Swift、Animation/" style="font-size: 14px;">Swift、Animation</a> <a href="/tags/学习/" style="font-size: 24px;">学习</a> <a href="/tags/我/" style="font-size: 14px;">我</a> <a href="/tags/算法/" style="font-size: 14px;">算法</a> <a href="/tags/项目/" style="font-size: 14px;">项目</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay subscribe-overlay">
    <div class="search-form">
        
        <img class="search-overlay-logo" src="https://i.loli.net/2017/11/26/5a19c0b50432e.png" alt="Ghcoder">
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>


<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<section class="copyright">
			<a href="/" title="Ghcoder">Ghcoder</a>
			&copy; 2018
		</section>
		<nav class="site-footer-nav">
			
            <a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
            <a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
        </nav>
    </div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations()
        .then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister();
            }
        });
    }
</script>







<div class="floating-header">
	<div class="floating-header-logo">
        <a href="/" title="Ghcoder">
			
                <img src="https://i.loli.net/2017/11/26/5a19c0b50432e.png" alt="Ghcoder icon">
			
            <span>Ghcoder</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">学习爬虫Scrapy[官网教程]</div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>





<script src="/js/mix/post-lazy-local.min.js"></script>

<script>;(function() {var bLazy = new Blazy()})();</script>




<script src="/js/lightgallery.min.js"></script>
<link rel="stylesheet" href="/css/lightgallery.min.css">
<script>
    lightGallery(document.getElementById('lightgallery'), {
        selector: '.post-img'
    });
</script>









<script>searchFunc("/")</script>





</body>
</html>
